# larajobs

```elixir
Mix.install([
  {:kino, github: "livebook-dev/kino", override: true},
  {:kino_lab, "~> 0.1.0-dev", github: "jonatanklosko/kino_lab"},
  # {:kino_vega_lite, "~> 0.1.1"},
  # {:kino_db, "~> 0.1.1"},
  {:req, github: "wojtekmach/req"},
  {:floki, "~> 0.32"},
  {:nimble_csv, "~> 1.1"},
  {:timex, "~> 3.0"}
])
```

## Summary

Using the excellent `req` library, we want to get the list of jobs from the jobs site.
The bulk of our notebooks use `spider man` but that is generally better suited to crawling paginated results. A number of sites stuff everything into the immediate response and use javascript to show/hide the results by "page".

## Specifications

1. [x] Map job items
   1. [x] New jobs `#app .container div` (no classes applied)
   2. [x] Older jobs `#app .container div` (no classed applied)
2. [x] Gather fields
   1. [x] `date`
   2. [x] `title`
   3. [x] `company`
   4. [x] `location`
   5. [x] `tags`
   6. [x] `source_url`
   7. [x] `post_url`
3. [x] Store results as CSV
4. [x] Sort CSV file by `date`
5. [x] Convert date from relative textual representation to a rough date.
   1. We can't be too precise unfortunately so we'll just use the first of the month, etc.

## Code

### Get Items from Parsing HTML

<!-- livebook:{"break_markdown":true} -->

###

```elixir
parse_date = fn date ->
  # xd
  # xw
  # xmo
  day_groups = Regex.run(~r/(\d+?)d/, date, capture: :all_but_first)
  week_groups = Regex.run(~r/(\d+?)w/, date, capture: :all_but_first)
  month_groups = Regex.run(~r/(\d+?)mo/, date, capture: :all_but_first)

  days =
    case day_groups do
      [number] -> String.to_integer(number)
      nil -> 0
    end

  weeks =
    case week_groups do
      [number] -> String.to_integer(number)
      nil -> 0
    end

  months =
    case month_groups do
      [number] -> String.to_integer(number)
      nil -> 0
    end

  # IO.inspect(days, label: "days")
  # IO.inspect(weeks, label: "weeks")
  # IO.inspect(months, label: "months")
  Timex.shift(Timex.today(), days: -days)
  |> Timex.shift(weeks: -weeks)
  |> Timex.shift(months: -months)
end

base_url = "https://larajobs.com/"

req_html = Req.new(http_errors: :raise)

html = Req.get!(req_html, url: base_url).body

{:ok, document} = Floki.parse_document(html)

# There are 2 divs with no classes applied, these are our new and old posts
# Filter out the anchor tags we don't want, specifically /create and /hide
jobs =
  Floki.find(document, "#app .container :not(div.flex)")
  |> Enum.filter(&match?({"a", _, _}, &1))
  |> Enum.filter(&(!match?({"a", [{"href", "/create"}, _], _}, &1)))
  |> Enum.filter(&(!match?({"a", [{"href", "/hide"}, _], _}, &1)))

# jobs =
#   Floki.find(document, "#app .container div")
#   |> hd()
#   |> Floki.children(include_text: false)
#   |> Enum.filter(&match?({"a", _, _}, &1))

items =
  Enum.map(jobs, fn job ->
    # source_url = Floki.attribute(job, ".job-link", "href")
    # post_url = Floki.attribute(job, ".job-link", "data-url")
    source_url = Floki.attribute(job, ".job-link", "href") |> hd()
    post_url = Floki.attribute(job, ".job-link", "data-url") |> hd()

    title = Floki.find(job, ".job-wrap .details .description") |> Floki.text() |> String.trim()
    company = Floki.find(job, ".job-wrap .details h4") |> Floki.text() |> String.trim()
    location = Floki.find(job, ".job-wrap .details div.text") |> Floki.text() |> String.trim()

    tags =
      Floki.find(job, ".job-wrap :not(div.details) .text-sm")
      |> Enum.map(&(&1 |> Floki.text() |> String.trim()))
      |> Enum.join(" | ")

    date_1 =
      Floki.find(job, ".job-link > div:last-child > div:nth-child(1)")
      |> Floki.text()
      |> String.trim()

    date_2 =
      Floki.find(job, ".job-link > div:last-child > div:nth-child(2)")
      |> Floki.text()
      |> String.trim()

    # The date field is either the 1st or 2nd child depending on age
    # If the first value is empty, the date will be the second field.
    # If the second value is "Apply", the pin element is not present and it's pulling the Apply button text
    date =
      cond do
        date_1 == "" && date_2 != "" -> date_2
        date_1 != "" && date_2 == "Apply" -> date_1
        true -> ""
      end

    full_date = parse_date.(date)
    # IO.inspect(title, label: "title")
    # IO.inspect(company, label: "company")
    # IO.inspect(location, label: "location")
    # IO.inspect(tags, label: "tags")
    # IO.inspect(date_1, label: "date_1")
    # IO.inspect(date_2, label: "date_2")
    # IO.inspect(date, label: "date")
    # IO.inspect(source_url, label: "source_url")
    # IO.inspect(post_url, label: "post_url")
    # IO.inspect(job, label: "job")

    %{
      date: full_date,
      title: title,
      company: company,
      location: location,
      tags: tags,
      source_url: source_url,
      post_url: post_url
    }
  end)

# IO.inspect(jobs_elements, label: "jobs_elements")

items
```

### Write Items to CSV

```elixir
alias NimbleCSV.RFC4180, as: CSV

take = fn item, header_keys ->
  Enum.map(header_keys, &Map.get(item, &1))
end

header_keys = [
  :date,
  :title,
  :company,
  :location,
  :tags,
  :source_url,
  :post_url
]

sorted_path = "./data/larajobs-sorted.csv"
File.rm_rf(sorted_path)
io_device = File.open!(sorted_path, [:write, :append, :binary, :utf8])

header = CSV.dump_to_iodata([header_keys])

csv =
  items
  |> Stream.map(&take.(&1, header_keys))
  |> CSV.dump_to_iodata()

:ok = IO.write(io_device, header)
:ok = IO.write(io_device, csv)
:ok = File.close(io_device)
```
